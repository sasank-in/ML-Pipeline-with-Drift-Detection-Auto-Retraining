# ğŸš€ Real-Time ML Pipeline with Auto-Retraining & Drift Detection

> A production-grade, microservices-based machine learning pipeline that automatically detects data drift and triggers model retraining in real-time.

[![Python](https://img.shields.io/badge/Python-3.9+-blue.svg)](https://www.python.org/)
[![Docker](https://img.shields.io/badge/Docker-Ready-brightgreen.svg)](https://www.docker.com/)
[![License](https://img.shields.io/badge/License-MIT-yellow.svg)](LICENSE)
[![MLOps](https://img.shields.io/badge/MLOps-Production%20Ready-orange.svg)]()

## ï¿½ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ML Pipeline System                        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Ingestion   â”‚â”€â”€â”€â–¶â”‚  Prediction  â”‚â”€â”€â”€â–¶â”‚    Drift     â”‚
â”‚     API      â”‚    â”‚   Service    â”‚    â”‚   Monitor    â”‚
â”‚   :8001      â”‚    â”‚    :8002     â”‚    â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                               â”‚
                                               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Dashboard   â”‚â—€â”€â”€â”€â”‚   Database   â”‚â—€â”€â”€â”€â”‚  Retraining  â”‚
â”‚   :8050      â”‚    â”‚   (SQLite)   â”‚    â”‚    Worker    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                           â”‚
                           â–¼
                    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                    â”‚   MLFlow     â”‚
                    â”‚   Registry   â”‚
                    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
automl_stream/
â”‚
â”œâ”€â”€ services/                    # Microservices
â”‚   â”œâ”€â”€ ingestion_api/          # Data ingestion endpoint
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”œâ”€â”€ prediction_service/     # Model serving
â”‚   â”‚   â”œâ”€â”€ app.py
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â”œâ”€â”€ drift_monitor/          # Drift detection
â”‚   â”‚   â”œâ”€â”€ monitor.py
â”‚   â”‚   â””â”€â”€ Dockerfile
â”‚   â””â”€â”€ retraining_worker/      # Auto-retraining
â”‚       â”œâ”€â”€ worker.py
â”‚       â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ ml/                          # ML components
â”‚   â”œâ”€â”€ training/
â”‚   â”‚   â””â”€â”€ trainer.py          # Model training
â”‚   â”œâ”€â”€ evaluation/
â”‚   â”‚   â””â”€â”€ drift_detector.py   # Drift detection algorithms
â”‚   â””â”€â”€ feature_store/          # Feature management
â”‚
â”œâ”€â”€ registry/                    # Model registry
â”‚   â””â”€â”€ mlflow/
â”‚       â””â”€â”€ mlflow_client.py    # MLFlow integration
â”‚
â”œâ”€â”€ dashboards/                  # Monitoring UI
â”‚   â”œâ”€â”€ monitoring_app.py       # Dash dashboard
â”‚   â””â”€â”€ Dockerfile
â”‚
â”œâ”€â”€ shared/                      # Shared utilities
â”‚   â”œâ”€â”€ config.py               # Configuration
â”‚   â”œâ”€â”€ database.py             # Database manager
â”‚   â”œâ”€â”€ logger.py               # Logging
â”‚   â””â”€â”€ redis_client.py         # Cache/Queue
â”‚
â”œâ”€â”€ docker-compose.yml           # Orchestration
â”œâ”€â”€ requirements.txt             # Dependencies
â””â”€â”€ README.md                    # This file
```

## ğŸš€ Quick Start

### Prerequisites
- Docker & Docker Compose
- Python 3.9+ (for local development)

### Run with Docker Compose

```bash
# Start all services
docker-compose up -d

# View logs
docker-compose logs -f

# Stop all services
docker-compose down
```

### Services & Ports

| Service | Port | Description |
|---------|------|-------------|
| Ingestion API | 8001 | Data ingestion endpoint |
| Prediction Service | 8002 | Model predictions |
| Drift Monitor | - | Background drift detection |
| Retraining Worker | - | Background retraining |
| Dashboard | 8050 | Monitoring UI |

### Access Dashboard

Open browser: `http://localhost:8050`

## ğŸ’» Local Development

### Setup

```bash
# Create virtual environment
python -m venv venv
source venv/bin/activate  # Windows: venv\Scripts\activate

# Install dependencies
pip install -r requirements.txt
```

### Run Services Individually

```bash
# Terminal 1: Ingestion API
python services/ingestion_api/app.py

# Terminal 2: Prediction Service
python services/prediction_service/app.py

# Terminal 3: Drift Monitor
python services/drift_monitor/monitor.py

# Terminal 4: Retraining Worker
python services/retraining_worker/worker.py

# Terminal 5: Dashboard
python dashboards/monitoring_app.py
```

## ğŸ“Š API Usage

### 1. Ingest Data

```bash
curl -X POST http://localhost:8001/ingest/batch \
  -H "Content-Type: application/json" \
  -d '{
    "features": [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]],
    "labels": [0, 1],
    "batch_id": "batch_001"
  }'
```

### 2. Make Predictions

```bash
curl -X POST http://localhost:8002/predict \
  -H "Content-Type: application/json" \
  -d '{
    "features": [[1.0, 2.0, 3.0], [4.0, 5.0, 6.0]]
  }'
```

### 3. Health Checks

```bash
# Check all services
curl http://localhost:8001/health  # Ingestion
curl http://localhost:8002/health  # Prediction
```

## ğŸ”„ How It Works

### 1. Data Flow
1. **Ingestion API** receives data and queues it
2. **Prediction Service** makes predictions using active model
3. Predictions are buffered for drift monitoring

### 2. Drift Detection
1. **Drift Monitor** periodically checks recent predictions
2. Uses KS-test, PSI, and statistical analysis
3. Triggers retraining if drift detected

### 3. Auto-Retraining
1. **Retraining Worker** picks up retraining jobs
2. Trains new model with recent data
3. Logs to MLFlow and registers model
4. Notifies Prediction Service to reload

### 4. Monitoring
1. **Dashboard** displays real-time metrics
2. Shows accuracy trends, drift events, predictions
3. Updates every 5 seconds

## ğŸ¯ Key Features

### Microservices Architecture
âœ… Independent, scalable services  
âœ… Docker containerization  
âœ… Service discovery and health checks  

### Drift Detection
âœ… Multiple statistical tests (KS, PSI, distribution)  
âœ… Configurable thresholds  
âœ… Feature-level drift analysis  

### Auto-Retraining
âœ… Triggered by drift detection  
âœ… MLFlow experiment tracking  
âœ… Model versioning and registry  

### Monitoring
âœ… Real-time dashboard  
âœ… Performance metrics  
âœ… Drift visualization  
âœ… Training history  

### Production Ready
âœ… Logging and error handling  
âœ… Database persistence  
âœ… Caching with Redis  
âœ… Configuration management  

## ğŸ§ª Testing

```bash
# Run tests
pytest tests/ -v

# With coverage
pytest tests/ --cov=. --cov-report=html
```

## ï¿½ Monitoring Dashboard

The dashboard provides:

- **Statistics Cards**: Total predictions, drift events, retraining count, accuracy
- **Accuracy Chart**: Model performance over time
- **Drift Chart**: Drift detection events
- **Prediction Distribution**: Class distribution
- **Training Time**: Time per retraining job

## âš™ï¸ Configuration

Edit `shared/config.py` to customize:

```python
# Model parameters
n_estimators = 100
max_depth = 10

# Drift detection
threshold = 0.05
window_size = 1000
check_interval = 300  # seconds

# Service ports
ingestion_port = 8001
prediction_port = 8002
dashboard_port = 8050
```

## ğŸ”§ Environment Variables

```bash
# Database
DB_HOST=localhost
DB_PORT=5432
DB_NAME=ml_pipeline

# Redis
REDIS_HOST=localhost
REDIS_PORT=6379

# MLFlow
MLFLOW_TRACKING_URI=http://localhost:5000
MLFLOW_EXPERIMENT=drift_detection_pipeline
```

## ï¿½ Database Schema

### predictions
- Stores all predictions with features and labels

### drift_events
- Logs drift detection results and actions

### training_jobs
- Tracks all training jobs and metrics

### model_registry
- Model versions and deployment status

## ğŸš¢ Deployment

### Production Considerations

1. **Replace SQLite with PostgreSQL**
2. **Use real Redis for caching/queues**
3. **Add authentication (JWT)**
4. **Implement rate limiting**
5. **Set up Prometheus/Grafana monitoring**
6. **Use Kubernetes for orchestration**
7. **Add CI/CD pipeline**

### Kubernetes Deployment

```bash
# Apply configurations
kubectl apply -f k8s/

# Check status
kubectl get pods
kubectl get services
```

## ğŸ“ For Final Year Project

This project demonstrates:

âœ… **Microservices Architecture** - Industry-standard design  
âœ… **MLOps** - Complete ML lifecycle management  
âœ… **Real-Time Systems** - Stream processing  
âœ… **Drift Detection** - Statistical analysis  
âœ… **Auto-Retraining** - Automated ML pipeline  
âœ… **Monitoring** - Real-time dashboards  
âœ… **Docker** - Containerization  
âœ… **API Design** - RESTful services  
âœ… **Database Design** - Data persistence  
âœ… **Testing** - Unit and integration tests  

## ğŸ“š Documentation

- [Technical Documentation](DOCUMENTATION.md)
- [API Reference](API.md)
- [Deployment Guide](DEPLOYMENT.md)

## ğŸ¤ Contributing

1. Fork the repository
2. Create feature branch
3. Commit changes
4. Push to branch
5. Create Pull Request

## ğŸ“„ License

MIT License - Free to use for your final year project!

## ğŸ‘¨â€ğŸ’» Author

[Your Name] - Final Year Project 2024

## ğŸ™ Acknowledgments

Built with modern MLOps practices and microservices architecture.
